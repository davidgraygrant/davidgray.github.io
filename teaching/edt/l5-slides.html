<!DOCTYPE html>
<html>
  <head>
    <title>EDT L5 Consequentialism</title>
    <meta charset="utf-8">
    <link href="remark-dgg.css" rel="stylesheet" type="text/css" media="all">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body>
<textarea id="source">

class: sectiontitle

# L5 Consequentialism

---

# Agenda

1. Initial case study discussion
2. Public health ethics
3. Classical utilitarianism

---

![image-20220124124900106](image-20220124124900106.png# w-75pct)

---

![image-20220124124928465](image-20220124124928465.png# w-60pct)

---

# Case study: GUIDE

**GUIDE** = decison support algorithm

- Developed by researchers at USC CAIS
- *Goal:* optimize TND intervention
- Advanced AI planning techniques

---

# Towards No Drug Abuse (TND)

- 6-week intervention 

- Conducted by social workers in residential shelters for homeless youth

- Train “peer leaders” to lead interactive sessions on healthy substance use behaviors

- Demonstrated effectiveness with high-risk populations

---

# A problem

**Deviancy training** – peers encourage harmful or antisocial behaviors

- Observed in trials of TND

- Success depends on allocation of participants to intervention groups

---

# AI-based solution

Use AI to identify the “best” set of intervention groups

1. Operationalize “best” by specifying **objective function**

2. Use **mathematical optimization** to identify near-optimal solutionChosen objective function

Initial objective function:  the optimal grouping of participants into participation groups is the grouping that will result in the lowest total number of users following the intervention

---

# Network-based interventions

---

# Initial discussion questions

1. Who are the **stakeholders** in the case study – the individuals who might be affected, positively or negatively, by the behavior of the AI-based system in question? 

2. How might the behavior of the system lead to **accidents** as defined by Amodei et al. (2016) – situations where “a human designer had in mind a certain (perhaps informally specified) objective or task, but the system that was designed and deployed for that task produced harmful and unexpected results”?

---

class: compact, smaller

# A moral dilemma

**DILEMMA.** On early tests on sample data, researchers discovered a potential problem. Researchers fed previously collected data about the social networks of members of a particular population of homeless youth in Los Angeles, California (where the center is based) into the agent’s influence model, and then instructed the agent to recommend intervention groups for a hypothetical set of participants in that population. The agent made a surprising recommendation: it recommended that the intervention team put the youth currently at highest risk of drug abuse into one group, and divide the youth at lower risk among the remaining groups. The agent’s model, it turned out, had predicted that grouping the hypothetical participants in this way would result in a substantial reduction in aggregate future drug abuse for the lower-risk youth—at the cost of a substantial predicted increase in future drug abuse for the higher-risk youth. The expected decrease in risk for the lower-risk youth was great enough that, despite the increased risk for the higher-risk youth, the resulting grouping was optimal from the point of view of minimizing risk at the population level. CAIS researchers judged that the model’s predictions here were reliable enough for the risk of significant harm here to be genuine if the hypothetical intervention were actually conducted.

**Discussion question:** would it be morally wrong to conduct such an intervention?

---

class: sectiontitle

# Public health and utilitarianism

---

# TND Network-GUIDE is a public health intervention

What does that mean + what implications for how GUIDE ought to be designed

---

class: compact, smaller

# What is public health?

**Public health** = "the science and art of preventing disease"

In contrast with medicine, public health focuses on

-   preventing disease
-   promoting the health of populations

Public health activities include

-   promoting healthy lifestyles
-   researching disease/injury prevention
-   surveillance of cases/health indicators
-   responding to outbreaks

---

# Public health ethics as utilitarian

> "Public health \[is\] a utilitarian endeavor: 'Although public health
> measures have been undertaken for centuries, the philosophical basis of
> modern public health is generally considered to be **nineteenth century**
> **utilitarianism**' (Rothstein 2004: 176)"

---Stephen Holland, *Public Health Ethics*, 21

???

I.e., classical utilitarianism, an ethical theory developed by Bentham and Mill

- Jeremy Bentham (1748-1832)
- John Stuart Mill (1806-1873)

---

# **Questions**

"Public health is a utilitarian endeavor"

1.  What does this mean?
2.  If it's true, what are the implications for how GUIDE should be designed?
3.  Is it true?

---

# Classical utilitarianism

**Principle of utility**: you always ought to perform whatever action would produce the most happiness in the long run

---

class: img-center

![image-20220124122158900](image-20220124122158900.png)

---

class: smaller

# The drowning child

Suppose that you are are walking to class and come across a small child drowning in Lake Alice. No one else is around. You believe that you could jump in and save the child without any danger to yourself. However, your laptop is in your backpack, and you’ve strapped it so tightly to yourself that you won’t have time to get it off. So, if you jump in to save the child, your laptop will be destroyed. You decide to continue on your way, leaving the child to drown.

1. Did you do something that was:

   - not wrong at all;

   - wrong but not seriously wrong; or

   - seriously wrong?

2. Why?

---

# Classical utilitarianism

**Principle of utility**: you always ought to perform whatever action would produce the most happiness in the long run

???

The principle of utility both gets the right result about the drowning child case and seems to explain why saving the child is the right thing to do

---

# Ethical theories

Ethical theories have two parts that answer different questions:

1.  A **theory of value**—what makes one way for the world to be
    better than another?
2.  A **theory of right action**—how are we obligated to act?

???

Classical utilitarianism is an ethical theory.

---

class: sectiontitle

# Theories of value

---

# What is valuable?

Examples of things that are valuable?

---

# Two kinds of value

**Final value**---*x* has final value just in case *x* is valuable for
its own sake

-   e.g., pleasure

**Instrumental value**---*x* has instrumental value just in case *x*
can help produce something that is good for its own sake

-   e.g., money

--

.center[Examples of each from our list of valuable things?]

---

# Job of a theory of value

A **theory of value** tells us what makes one outcome better than
another

It does that by telling us

1.  what kinds of things have final value
2.  how valuable outcomes are, given the goods present

---

# Classical hedonism

1.  **Hedonism:** only happiness (pleasure and the absence of pain) is good for its own sake, and only unhappiness is bad for its own sake
2.  **Aggregation:** the total value of an outcome is the sum
    of the pleasure it contains minus the sum of the pain it contains

---

# Hedonism

**Hedonism:** only well-being, understood as pleasure and the absence of pain, is good for its own sake

- **Welfarism:** only well-being is good for its own sake

---

class: compact,  smaller

# The experience machine

> Suppose there were an experience machine that would give you any experience you desired. Superduper neuropsychologists could stimulate your brain so chat you would think and feel you were writing a great novel, or making a friend, or reading an interesting book. All the time you would be floating in a tank, with electrodes attached to your brain. Should you plug into this machine for life, preprogramming your life’s experiences? If you are worried about missing out on desirable experiences, we can suppose that business enterprises have researched thoroughly the lives of many others. You can pick and choose from their large library or smorgasbord of such experiences, selecting your life's experiences for, say, the next two years. After two years have passed, you will have ten minutes or ten hours out of the rank, to select the experiences of your next two years. Of course, while in the tank you won't know that you're there; you'll think it’s all actually happening. Others can also plug in to have the experiences they want, so there’s no need to stay unplugged to serve them. (Ignore problems such as who will service the machines if everyone plugs in.) Would you plug in? *What else can matter to us, other than how our lives feel from the inside?*

—Robert Nozick, *Anarchy, State, and Utopia* (1974).

---

class: smaller, compact

# The experience machine

Discussion questions:

1. Would a **hedonist** advise you to plug in? Why or why not?

2. Would **you** plug into the machine for life? Why or why not?
3. What does the thought experiment teach us about what has **final value**?

Clarifications:

- You have to plug in for life or not at all
- Assume everyone else's needs are taken care of
- You don't know you are in the machine
- Assume the experiences will be *really* enjoyable
- Any people you interact with are just simulations

---

# Hedonism and the experience machine

**Hedonism:** only well-being, understood as pleasure and the absence of pain, is good for its own sake

- **Welfarism:** only well-being is good for its own sake

---

# Aggregation

**Aggregation:** the total value of an outcome is the sum of the pleasure it contains minus the sum of the pain it contains

???

Examples

- Six people are having an ok day (20 each) = 120
- Five people are having a good day (30 each), one person is suffering moderately (-30) = 120
- One person is ecstatic (100), five people are having a blah day (10 each) = 150

---

# Classical hedonism

1.  **Hedonism:** only happiness (pleasure and the absence of pain) is good for its own sake, and only unhappiness is bad for its own sake
2.  **Aggregation:** the total value of an outcome is the sum
    of the pleasure it contains minus the sum of the pain it contains

???

Brief recap

---

class: sectiontitle

# Theories of right action

---

# Three moral properties of actions

1. **prohibited**—doing it would be wrong
   - e.g., kicking puppies for no reason
2. **permissible**—doing it would not be wrong
   - e.g., brushing your teeth with your right hand
3. **obligatory**—not doing it would be wrong
   - e.g., keeping a promise

???

Moral properties an action can have

Moral permissibility, obligation, and prohibition are
interdefinable

-   X is obligatory just in case not X is prohibited

    -   giving to charity is obligatory just in case not giving to
        charity is prohibited
-   X is prohibited just in case it is not the case that not X is obligatory
    -   kicking puppies for no reason is prohibited just in case it is not the case that not kicking puppies for no reason is obligatory

-   X is permissible just in case X is not prohibited

    -   listening to Justin Bieber is permissible just in case it is not
        the case that listening to Justin Bieber is prohibited

---

# Job of a theory of right action

A **theory of right action** tells us how we are obligated to act

-   It does that by telling us the conditions under which
    actions are morally permissible
-   It doesn't tell us which specific actions are morally
    permissible

---

# Consequentialism and non-consequentialism

**Consequentialism:** whether an action is morally permissible is
determined exclusively by how good its consequences would be,
relative to other possible actions

-   *Slogan:* how could it be wrong to do the thing that would have the
    very best consequences?

**Non-consequentialism:** whether an action is morally permissible is
not determined exclusively by how good its consequences would
be

-   *Slogan:* there are some things you shouldn't do, no matter how good
    the consequences would be!

---

# Classical utilitarianism 

 Classical utilitarians accept two claims

1.  **Classical hedonism:** an outcome is good to the extent that it
    contains more happiness (pleasure - pain)
2.  **Act consequentialism:** an action is morally permissible just in case it would produce the best possible outcome of all the actions available

???

Example consequentialist theory accepted by Bentham and Mill

---

class: small

# Act consequentialism

“An action is morally required just because it produces the best overall results (i.e., is optimific)”

--

1. Identify what is good for its own sake (has final value)
2. Identify what is bad for its own sake
3. Determine all your options (actions open to you at the moment)
4. For each option, determine the value of its results. How much of what is good/bad for its own sake will each produce?
5. Pick the option that yields the best balance—the greatest total amount of value. That's the morally right or obligatory action. Any other action would be wrong.

???

Under what conditions does an action produce the best overall results?

Explain how this applies to the drowning child case

---

# Is public health utilitarian?

> Public health \[is\] a utilitarian endeavor: 'Although public health
> measures have been undertaken for centuries, the philosophical basis of
> modern public health is generally considered to be **nineteenth century**
> **utilitarianism**' (Rothstein 2004: 176)

—Stephen Holland, *Public Health Ethics*, 21

---

class: compact, small

# Public health ethics as utilitarian

**Classical hedonism:** an outcome is good to the extent that it
contains more happiness (pleasure - pain)

-   Public health focuses on promoting health, which is an important component of happiness

**Act consequentialism:** an action is morally permissible just in case it would produce the best
possible outcome of all the actions available

-   Goal of public health is to promote the interests of populations, not the individual
-   Interventions typically aim to maximize population-level benefits

---

# An argument that public health is utilitarian

> The aim of public health is to benefit populations of people by
> protecting and promoting their health status. So, a simple formula
> suggests itself: utilitarianism says that the morally right thing to do
> is to maximize benefit; health is a benefit; therefore, any public
> health policy that will produce maximal health gain is morally justified
> (even obligatory).

—Stephen Holland, *Public Health Ethics*, 21

???

Holland calls this the "naïve utilitarian" view of public health

- He calls it naive because he think's it's not the whole story about when public health interventions are morally justified

---

# Similar arguments

Utilitarianism says that the morally right thing to do is to maximize benefit; health is a benefit; therefore, any public health policy that will produce maximal health gain is morally justified.

Utilitarianism says that the morally right thing to do is to maximize benefit; income is a benefit; therefore, any government policy that will produce maximal income growth is morally justified.

Utilitarianism says that the morally right thing to do is to maximize benefit; free tacos are a benefit; therefore, any government policy that will provide people with as many tacos as possible is morally justified.

---

class: compact, smaller

# Act utilitarianism and GUIDE

**DILEMMA.** On early tests on sample data, researchers discovered a potential problem. Researchers fed previously collected data about the social networks of members of a particular population of homeless youth in Los Angeles, California (where the center is based) into the agent’s influence model, and then instructed the agent to recommend intervention groups for a hypothetical set of participants in that population. The agent made a surprising recommendation: it recommended that the intervention team put the youth currently at highest risk of drug abuse into one group, and divide the youth at lower risk among the remaining groups. The agent’s model, it turned out, had predicted that grouping the hypothetical participants in this way would result in a substantial reduction in aggregate future drug abuse for the lower-risk youth—at the cost of a substantial predicted increase in future drug abuse for the higher-risk youth. The expected decrease in risk for the lower-risk youth was great enough that, despite the increased risk for the higher-risk youth, the resulting grouping was optimal from the point of view of minimizing risk at the population level. CAIS researchers judged that the model’s predictions here were reliable enough for the risk of significant harm here to be genuine if the hypothetical intervention were actually conducted.

**Discussion question:** would it be morally wrong to conduct such an intervention?

</textarea>

<script src="https://remarkjs.com/downloads/remark-latest.min.js">
</script>
<script>
  var slideshow = remark.create({
    ratio:'16:9'
  });
</script>
  </body>
</html>