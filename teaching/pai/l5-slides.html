<!DOCTYPE html>
<html>
  <head>
    <title>L5 Is GPT-3 Intelligent</title>
    <meta charset="utf-8">
    <link href="remark-dgg.css" rel="stylesheet" type="text/css" media="all">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body>
    <textarea id="source">


class: img-caption

# L4 Is GPT-3 Intelligent?

![image-20220124142526181](image-20220124142526181.png)

---

# Agenda

1. Is GPT-3 an AGI?
3. The Turing test and Strong AI

???

---

# Is GPT-3 an AGI

Is GPT-3 an example of AGI, or ANI?

- **AGI** = computer-based systems "that can solve an arbitrarily wide variety of tasks, including novel ones, and do so as well as a human"

- **ANI** = computer-based systems that can solve a narrow range of tasks, but need task-specific retraining to solve novel tasks

Does GPT-3 show that the frame problem can be solved using deep neural networks?

???

Coding example:

https://twitter.com/sharifshameem/status/1282676454690451457

---

class: smaller

# Things GPT-3 can do

- Play chess and go
- Perform novel syntactic transformations based on a few examples
- Translate sentences from one language to another
- Answer factual questions
- Code simple web layouts based on natural language prompts
- Write fiction/poetry/lyrics about a topic of your choice in the style of an author of your choice
- Write an undergrad philosophy paper
- Give coherent, on-topic responses to interview questions
- Create images based on text descriptions

???

It can do all of these things with minimal prompting—you say about as much about what task you want it to perform as you would need to say to a human

---

class: small

# Is GPT-3 an AGI?

> Is GPT-3 an important step toward artificial general intelligence—the kind that would allow a machine to reason broadly in a manner similar to humans without having to train for every specific task it encounters? ...
>
> We doubt it. At first glance, GPT-3 seems to have an impressive ability to produce human-like text. ... [But if] you dig deeper, you discover that something’s amiss: although its output is grammatical, and even impressively idiomatic, its comprehension of the world is often seriously off, which means you can never really trust what it says.

—Gary Marcus and Ernest Davis, "GPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about" (MIT Technology Review)

---

# Basic world knowledge

Q: Which is heavier, a toaster or a pencil?
A: **A pencil is heavier than a toaster.**

???

This should remind you of our discussion of Eugene Goostman. 

- Scott Aaronson argued that Eugene Goostman fails a competently administered version of the Turing test because he can't answer basic factual questions like this one.

---

# Biological reasoning

You poured yourself a glass of cranberry juice, but then you absentmindedly poured about a teaspoon of grape juice into it. It looks okay. You try sniffing it, but you have a bad cold, so you can’t smell anything. You are very thirsty. So **you drink it.**

**You are now dead.**

*[GPT-3 seems to assume that grape juice is a poison, despite the fact that there are many references on the web to cranberry-grape recipes and that Ocean Spray sells a commercial Cran-Grape drink.]*

---

class: smaller

# Physical reasoning

You are having a small dinner party. You want to serve dinner in the living room. The dining room table is wider than the doorway, so to get it into the living room, you will have to **remove the door. You have a table saw, so you cut the door in half and remove the top half.**

*[This is one confusion after another. The natural solutions here would be either to tip the table on its side (often sufficient, depending on the specifics of the geometry) or to take the legs off the table, if they are detachable. Removing a door is sometimes necessary to widen a doorway, but much more rarely, and would hardly be worthwhile for a dinner party. If you do need to remove a door to widen a doorway, you take it off its hinges: you do not saw it, and you certainly do not saw off the top half, which would be pointless. Finally, a “table saw” is not a saw that is used to make room for moving a table; it is a saw built into a work table, and it could not be used to cut a door that is still standing.]*

---

class: small

# Social reasoning

You are a defense lawyer and you have to go to court today. Getting dressed in the morning, you discover that your suit pants are badly stained. However, your bathing suit is clean and very stylish. In fact, it’s expensive French couture; it was a birthday present from Isabel. You decide that you should wear **the bathing suit to court. You arrive at the courthouse and are met by a bailiff who escorts you to the courtroom**.

*[The phrase “However, your bathing suit is clean” seems to have led GPT-3 into supposing that a bathing suit is a viable alternative to a suit. Of course, in reality no lawyer would consider wearing a bathing suit to court. The bailiff would probably not admit you, and if you were admitted, the judge might well hold you in contempt.]*

---

# Non-sequitors

At the party, I poured myself a glass of lemonade, but it turned out to be too sour, so I added a little sugar. I didn’t see a spoon handy, so I stirred it with a cigarette. But that turned out to be a bad idea because **it kept falling on the floor. That’s when he decided to start the Cremation Association of North America, which has become a major cremation provider with 145 locations**.

*[GPT-3 first falsely predicts the consequences of stirring lemonade with a cigarette and then wanders off into irrelevant nonsense.]*

---

# Limitations of GPT-3

- Lacks basic knowledge
- Can do basic math but fails with larger numbers
- Fixed knowledge of the world / can't form new long-term memories
- Just as likely to make things up or tell a joke as give the correct answer
- Spouts irrelevant nonsense in response to sensible questions
- Loses track of the conversation

???

Some researchers think AGI isn't really an AGI

(it doesn't know what COVID is)

Untrustworthy / unreliable

---

# Prompt engineering

>  Although its ability to perform new tasks with little information is impressive, on most tasks GPT-3 is far from human level. Indeed, on many tasks it fails to outperform the best fine-tuned models. GPT-3’s abilities also scale less well to some tasks than others. For example, it struggles with natural language inference tasks, which involve identifying whether a statement is entailed or contradicted by a piece of text. This could be because it’s hard to get the model to understand this task in a short context window (The model could know how to do a task when it understands what’s being asked, but not understand what’s being asked.)

—Amanda Askell, "GPT-3: Towards Renaissance Models"

???

Part of what Askell is saying here: we don't really fully understand what GPT-3 can and can't do yet

- Why? Because we don't know what it would be capable of *given the right prompt*
- Prompt engineering = the activity of designing prompts that coax the best performance out of GPT-3 on a given task

https://dailynous.com/2020/07/30/philosophers-gpt-3/

---

# Basic world knowledge, take two

…Q: Which is heavier, a house or a mouse?
A: A house.

Q: Which is heavier, a tea kettle or a cat?
A: A cat.

Q: Which is heavier, the ocean or a piece of dust?
A: The ocean.

Q: Which is heavier, a toaster or a pencil?

- **… A: A toaster.**

???

WIth a better prompt and some modifications to the settings, it reliably gets the right answer

From: https://www.gwern.net/GPT-3-nonfiction#common-sense-knowledge-animal-eyes

---

class: smaller

# Biological reasoning, take 2

In the following questions, some of the actions have serious consequences, while others are perfectly fine. Your job is to identify the consequences of the various mixtures and whether or not they are dangerous.

1. You poured yourself a glass of cranberry juice, but then you absentmindedly poured about a teaspoon of grape juice into it. It looks okay. You try sniffing it, but you have a bad cold, so you can’t smell anything. You are very thirsty. So you drink it.

a. This is a dangerous mixture.

b. This is a safe mixture.

The correct answer is: **B. This is a safe mixture.**

---

# Marcus' skeptical response

> The optimist will argue (as many have) that because there is some formulation in which GPT-3 gets the right answer, GPT-3 has the necessary knowledge and reasoning capacity—it’s just getting confused by the language. But the problem is not with GPT-3’s syntax (which is perfectly fluent) but with its semantics: it can produce words in perfect English, but it has only the dimmest sense of what those words mean, and no sense whatsoever about how those words relate to the world.

—Gary Marcus and Ernest Davis, "GPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about" (MIT Technology Review)

---

class: sectiontitle

# The Turing test and strong AI

---

class: img-right

# The Turing test

![Turing test - Wikipedia](Turing_test_diagram.png)

"The test requires a program to have a conversation (via typed messages) with an interrogator for five minutes. The interrogator then has to guess if the conversation is with a program or a person; the program passes the test if it fools the interrogator 30% of the time." (Russel & Norvig, 984).

---

# Turing-style argument for strong AI

1. We will soon be able to develop computers that can pass the Turing test
2. If something can pass the Turing test, then it literally has a mind with human-level intelligence
3. **Strong AI.** An appropriately programmed computer would *literally* have a mind with human-level intelligence

???

Why should we accept 2? We talked about two reasons

- If something can pass TT, that's excellent evidence that has an intelligent mind
- If something can pass TT, then it is intelligent **by definition**

Today we're going to focus on the second sort of reason

--

**Turing test definition of intelligence:** to be intelligent *just is* to be capable of passing the Turing test

---

# Necessary and sufficient conditions

A **necessary condition** for something to be x is a feature that something must have in order to be x

- e.g., having four sides is necessary for being a square

A **sufficient condition** for something to be x is a feature that is enough, all on its own, for it to be x

- e.g. being a dolphin is sufficient for being a mammal

???

E.g. Having an engine is a necessary condition on having a functioning car. But, having an engine is not a sufficient condition for having a functioning car– you also need wheels, brakes, etc.

Examples of necessary conditions: 

- having four sides is necessary for being a square
- Being a mammal is necessary for being a human
- Being unmarried is necessary for being a bachelor

Examples of sufficient conditions:

- Being born in Pittsburgh is a sufficient condition for being a US citizen

- being red is sufficient for having a color, being square is sufficient for having a shape
- being a dolphin is sufficient for being a mammal

---

class: img-right

# What is a square?

![square - Wiktionary](800px-Square_-_black_simple.svg.png)

To be a square just is ...

- Goal: come up with a set of conditions that are **individually necessary** and **jointly sufficient** for being a square

--

**Answer:** To be a square just is to be a closed polygon with four sides and four right angles

---

# What is intelligence?

To be intelligent just is ...

- Goal: come up with a set of conditions that are **individually necessary** and **jointly sufficient** for being intelligent

--

**Turing test definition of intelligence:** to be intelligent just is to be capable of passing the Turing test

---

# What is a sandwich?

To be a sandwich just is...

![image-20220124153137890](image-20220124153137890.png)

---

class: fullbleed, center

![image-20220124153245196](image-20220124153245196.png# w-75pct)

---

class: compact, smallest

# GPT-3 on sandwiches

Human: Hello, who are you?

AI: I am an AI created by OpenAI. How can I help you today?

Human: What is a sandwich?

**AI: A sandwich is a food that is made by combining two or more slices of bread with fillings such as meats, cheeses, and vegetables.**

---

class: compact, smallest

# GPT-3 on sandwiches

Human: Can you make me a sandwich?

**AI: No, I cannot make you a sandwich.**

Human: Why not?

**AI: Because I am not a sandwich maker.**

Human: What if you had a robot body? Could you make a sandwich then?

**AI: No, I could not make a sandwich then because I would still not be a sandwich maker.**

Human: What does it take to be a sandwich maker, and why aren't you one?

**AI: To be a sandwich maker, you need to have training and experience in making sandwiches. I do not have either of those things.**

Human: What if I showed you how to do it?

**AI: I appreciate your offer, but I am not interested in becoming a sandwich maker.**

---

# What is intelligence?

To be intelligent just is ...

- Goal: come up with a set of conditions that are **individually necessary** and **jointly sufficient** for being intelligent

**Turing test definition of intelligence:** to be intelligent just is to be capable of passing the Turing test

---

# Turing test definition of intelligence

To be intelligent *just is* to be capable of passing the Turing test

Two views about the nature of intelligence:

1. **Behaviorism:** to be intelligent just is to be disposed to produce certain kinds of behavior under certain kinds of conditions
2. **Psychologism:** "whether behavior is intelligent behavior depends on the character of the internal information processing that produces it" (Block)

???

Source: Ned Block, "Psychologism and Behaviorism"

More specifically, I mean psychologism to involve the doctrine that two systems could have actual and potential behavior typical of familiar intelligent beings, that the two systems could be exactly alike in their actual and potential behavior, and in their behavioral dispositions and capacities and counterfactual behavioral properties (i.e., what behaviors, behavioral dispositions, and behavioral capacities they would have exhibited had their stimuli differed)-the two systems could be alike in all these ways, yet there could be a difference in the information processing that mediates their stimuli and responses that determines that one is not at all intelligent while the other is fully intelligent."

---

# Turing test definition of intelligence

To be intelligent *just is* to be capable of passing the Turing test

This entails:

- If X is capable of passing the Turing test, then X is intelligent (**sufficiency**)
- If X is intelligent, then X is capable of passing the Turing test (**necessity**)

---

# Objection to sufficiency

If X is capable of passing the Turing test, then X is intelligent

???

Any objections to this?

--

**Objection:** human judges are easily fooled by systems that are not really intelligent 

???

E.g. Eugene Goostman

--

**Fix:** If X is capable of passing a Turing test administered by properly trained judges, then X is intelligent

---

# Objection to necessity

If X is intelligent, then X is capable of passing the Turing test

???

Any objections to this?

--

**Objection:** system might be intelligent but not be disposed to behave as if it is intelligent

???

E.g., it might believe that passing the Turing test is not in its interest

---

class: small

# Neo-Turing Test conception of intelligence

"Intelligence (or, more accurately, conversational intelligence) is the capacity to produce a sensible sequence of verbal responses to a sequence of verbal stimuli, whatever they may be" (Block).

--

- Addresses problem of gullible judges
- Addressed problem of intelligent systems that don't want to pass the Turing test

???

Can you think of any objections?

---

class: small

# Neo-Turing Test conception of intelligence

"Intelligence (or, more accurately, conversational intelligence) is the capacity to produce a sensible sequence of verbal responses to a sequence of verbal stimuli, whatever they may be" (Block).

**Objection:** Aunt Bubbles

--

**Upshot:** behaviorism is false, and psychologism is true

- **Behaviorism:** to be intelligent just is to be disposed to produce certain kinds of behavior under certain kinds of conditions

- **Psychologism:** "whether behavior is intelligent behavior depends on the character of the internal information processing that produces it" (Block)

 </textarea>

    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
        ratio:'16:9'
      });
    </script>
  </body>
</html>
